{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_files = os.listdir(\"../data/negative/\")\n",
    "positive_files = os.listdir(\"../data/positive/\")\n",
    "all_files = negative_files + positive_files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sequence from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_negative = \"../data/negative/\"\n",
    "path_positive = \"../data/positive/\"\n",
    "sequences = []\n",
    "for file in negative_files:\n",
    "    for record in SeqIO.parse(path_negative + file, \"fasta\"):\n",
    "        sequences.append(record.seq)\n",
    "\n",
    "for file in positive_files:\n",
    "    for record in SeqIO.parse(path_positive + file, \"fasta\"):\n",
    "        sequences.append(record.seq)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_sequence = [list(str(seq.lower())) for seq in sequences]\n",
    "data = {\n",
    "    \"sequences\": tokenize_sequence,\n",
    "}\n",
    "sequence_data = pd.DataFrame(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    vector_size=3,\n",
    "    window=10,\n",
    "    min_count=1,\n",
    "    workers=4,\n",
    "    sg=0,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(sequence_data, progress_per=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(sequence_data, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./vectors.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save vectors to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec(row=0):\n",
    "    vec_sentence = []\n",
    "    for i in sequence_data.iloc[row].explode():\n",
    "        try:\n",
    "            vec_sentence.append(model.wv[i.lower()])\n",
    "        except:\n",
    "            pass\n",
    "    return vec_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save vectors to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_data = pd.DataFrame(columns=[\"vectors\"])\n",
    "for index in range(sequence_data.shape[0]):\n",
    "    vector_data.loc[len(vector_data.index)] = [vec(index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DKMSQNGPTPPMYVKMSDIPSEHVIAGQHDGEAVRITKVV\n",
    "model.wv[\"t\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for line in f:\n",
    "#     values = line.split()\n",
    "#     word = values[0]\n",
    "#     vector = np.asarray(values[1:], \"float32\")\n",
    "#     embeddings_dict[word] = vector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3db0374a90da7e4aa6d0ffed9483f20254a6faf11dbe5d7ff0e3d9b0ad3a2d5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
